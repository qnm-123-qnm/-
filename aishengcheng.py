import streamlit as st
import random
from datetime import datetime
from openai import OpenAI

# -------------------------- é¡µé¢åŸºç¡€é…ç½® --------------------------
st.set_page_config(
    page_title="ScholarMind - å­¦æœ¯çµæ„Ÿå¼•æ“",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------------- è‡ªå®šä¹‰æ ·å¼ --------------------------
st.markdown("""
<style>
    .stTextInput, .stSelectbox, .stTextArea {
        border-radius: 8px;
        border: 1px solid #e0e0e0;
    }
    .result-card {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        margin: 10px 0;
        border-left: 4px solid #2196f3;
    }
    .citation {
        font-family: monospace;
        font-size: 0.9em;
        color: #333;
        background-color: #f0f0f0;
        padding: 8px;
        border-radius: 4px;
    }
    .highlight {
        color: #2196f3;
        font-weight: 600;
    }
    .api-tip {
        font-size: 0.9em;
        color: #666;
        margin-top: 5px;
    }
</style>
""", unsafe_allow_html=True)


# -------------------------- API é…ç½®ï¼ˆä»…ç½‘é¡µè¾“å…¥ï¼‰ --------------------------
def init_openai_client(api_key):
    """åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆä»…åŸºäºç½‘é¡µè¾“å…¥çš„å¯†é’¥ï¼‰"""
    if not api_key:
        st.warning("âš ï¸ æœªå¡«å†™APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå†…å®¹ï¼ˆæ— çœŸå®LLMèƒ½åŠ›ï¼‰")
        return None
    try:
        client = OpenAI(api_key=api_key.strip())
        # ç®€å•æ ¡éªŒå¯†é’¥æœ‰æ•ˆæ€§ï¼ˆè°ƒç”¨è½»é‡æ¥å£ï¼‰
        client.models.list()
        st.success("âœ… APIå¯†é’¥éªŒè¯é€šè¿‡ï¼")
        return client
    except Exception as e:
        st.error(f"âŒ APIå¯†é’¥æ— æ•ˆ/è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
        return None


# -------------------------- æ¨¡æ‹Ÿå­¦æœ¯æ•°æ®ï¼ˆå…œåº•ç”¨ï¼‰ --------------------------
CORE_LITERATURE = {
    "è®¡ç®—æœºç§‘å­¦/æœºå™¨å­¦ä¹ /å¤§æ¨¡å‹å¹»è§‰æŠ‘åˆ¶": [
        ("Li et al., 2024", "ã€ŠHallucination Suppression in LLMs via Knowledge Groundingã€‹",
         "IEEE Transactions on Pattern Analysis and Machine Intelligence"),
        ("Zhang et al., 2023", "ã€ŠA Survey on Hallucination Detection in Large Language Modelsã€‹",
         "ACM Computing Surveys"),
        ("Wang et al., 2022", "ã€ŠContrastive Learning for Reducing LLM Hallucinationsã€‹", "NeurIPS")
    ],
    "è®¡ç®—æœºç§‘å­¦/æœºå™¨å­¦ä¹ /å°æ ·æœ¬å­¦ä¹ ": [
        ("Chen et al., 2024", "ã€ŠFew-Shot Learning with Prompt Enhancementã€‹", "ICML"),
        ("Liu et al., 2023", "ã€ŠMeta-Learning for Low-Resource Few-Shot Tasksã€‹", "ICLR"),
        ("Zhao et al., 2022", "ã€ŠFew-Shot Classification via Feature Alignmentã€‹", "CVPR")
    ],
    "é»˜è®¤": [
        ("Author et al., 2024", "ã€ŠResearch on Core Issues in This Fieldã€‹", "Top Journal in the Field"),
        ("Author et al., 2023", "ã€ŠA Comprehensive Review of Recent Advancesã€‹", "Key Conference Proceedings"),
        ("Author et al., 2022", "ã€ŠChallenges and Future Directionsã€‹", "International Journal")
    ]
}

CITATION_FORMATS = {
    "APA 7th": "{authors} ({year}). {title}. {journal}.",
    "GB/T 7714": "{authors}. {title}[J]. {journal}, {year}.",
    "MLA 9th": "{authors}. \"{title}\". {journal}, vol. XX, no. XX, {year}, pp. XX-XX."
}


# -------------------------- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° --------------------------
def get_literature(field_key):
    """è·å–å¯¹åº”é¢†åŸŸçš„æ ¸å¿ƒæ–‡çŒ®"""
    return CORE_LITERATURE.get(field_key, CORE_LITERATURE["é»˜è®¤"])


def generate_topics(client, field, core_problem):
    """ç”Ÿæˆé€‰é¢˜ï¼ˆAPIä¼˜å…ˆï¼Œæ— åˆ™å…œåº•ï¼‰"""
    # æœ‰APIåˆ™è°ƒç”¨çœŸå®LLM
    if client:
        prompt = f"""
        ä½ æ˜¯èµ„æ·±å­¦æœ¯ç ”ç©¶å‘˜ï¼ŒåŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆ3ä¸ªåˆ›æ–°ã€å¯è¡Œçš„å­¦æœ¯é€‰é¢˜ï¼š
        1. å­¦ç§‘é¢†åŸŸï¼š{field}
        2. æ ¸å¿ƒç ”ç©¶é—®é¢˜ï¼š{core_problem}
        3. æ ¼å¼è¦æ±‚ï¼šé€‰é¢˜éœ€ç®€æ´ä¸“ä¸šï¼Œè´´åˆå½“å‰ç ”ç©¶çƒ­ç‚¹ï¼Œç¤ºä¾‹ï¼šã€ŒåŸºäºçŸ¥è¯†é”šå®šçš„å¤§æ¨¡å‹å¹»è§‰æŠ‘åˆ¶æ–¹æ³•ç ”ç©¶ã€
        """
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=500
            )
            topics = [t.strip() for t in response.choices[0].message.content.strip().split("\n") if t.strip()]
            return topics[:3]
        except Exception as e:
            st.warning(f"é€‰é¢˜ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å…œåº•æ•°æ®ï¼š{str(e)}")

    # æ— API/è°ƒç”¨å¤±è´¥åˆ™ç”¨æ¨¡æ‹Ÿé€»è¾‘
    methods = ["çŸ¥è¯†é”šå®š", "å¯¹æ¯”å­¦ä¹ ", "å…ƒå­¦ä¹ ", "æç¤ºå¢å¼º", "ç‰¹å¾å¯¹é½"]
    innovations = ["å› æœæ¨ç†", "å¤šæ¨¡æ€èåˆ", "è½»é‡åŒ–æ¨¡å‹", "äººæœºååŒ"]
    cross_fields = ["è®¤çŸ¥å¿ƒç†å­¦", "ç»Ÿè®¡å­¦", "åšå¼ˆè®º"]
    templates = [
        "åŸºäº{method}çš„{field}ä½èµ„æºåœºæ™¯{problem}é—®é¢˜ç ”ç©¶",
        "{field}ä¸­{problem}çš„å¯è§£é‡Šæ€§å¢å¼ºæ–¹æ³•ï¼š{innovation}è§†è§’",
        "èåˆ{cross_field}æ€æƒ³çš„{field} {problem}è§£å†³æ–¹æ¡ˆä¸å®è¯åˆ†æ"
    ]
    return [
        template.format(
            method=random.choice(methods),
            field=field,
            problem=core_problem,
            innovation=random.choice(innovations),
            cross_field=random.choice(cross_fields)
        ) for template in templates
    ]


def generate_literature_review(client, field, core_problem, literature_list):
    """ç”Ÿæˆæ–‡çŒ®ç»¼è¿°ï¼ˆAPIä¼˜å…ˆï¼Œæ— åˆ™å…œåº•ï¼‰"""
    if client:
        literature_str = "\n".join([f"{auth}: {title} ({journal})" for auth, title, journal in literature_list])
        prompt = f"""
        åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆç»“æ„åŒ–çš„æ–‡çŒ®ç»¼è¿°æ¡†æ¶ï¼ˆçº¦800å­—ï¼‰ï¼š
        1. å­¦ç§‘é¢†åŸŸï¼š{field}
        2. æ ¸å¿ƒç ”ç©¶é—®é¢˜ï¼š{core_problem}
        3. æ ¸å¿ƒæ–‡çŒ®ï¼š{literature_str}
        4. æ¡†æ¶è¦æ±‚ï¼šåŒ…å«ã€Œç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰ã€ã€Œå›½å†…å¤–ç ”ç©¶ç°çŠ¶ã€ã€Œç°æœ‰ç ”ç©¶ä¸è¶³ã€ã€Œæœ¬æ–‡ç ”ç©¶åˆ‡å…¥ç‚¹ã€4éƒ¨åˆ†ï¼Œè¯­è¨€ä¸“ä¸šã€é€»è¾‘æ¸…æ™°ã€‚
        """
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,
                max_tokens=1000
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            st.warning(f"ç»¼è¿°ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å…œåº•æ•°æ®ï¼š{str(e)}")

    # å…œåº•é€»è¾‘
    return f"""
### æ–‡çŒ®ç»¼è¿°æ¡†æ¶ï¼š{field} - {core_problem}
#### 1. ç ”ç©¶èƒŒæ™¯ä¸æ„ä¹‰
{field}ä½œä¸ºäººå·¥æ™ºèƒ½é¢†åŸŸçš„æ ¸å¿ƒæ–¹å‘ï¼Œè¿‘å¹´æ¥å–å¾—äº†å¿«é€Ÿå‘å±•ï¼Œä½†{core_problem}é—®é¢˜ä»åˆ¶çº¦ç€è¯¥é¢†åŸŸçš„å®é™…åº”ç”¨ä»·å€¼ï¼ŒäºŸå¾…æå‡ºæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

#### 2. å›½å†…å¤–ç ”ç©¶ç°çŠ¶
##### 2.1 æ ¸å¿ƒæ–¹æ³•åˆ†ç±»
- åŸºäºæ•°æ®å¢å¼ºçš„æ–¹æ³•ï¼šä»£è¡¨æ–‡çŒ®{literature_list[0][0]}æå‡ºäº†{literature_list[0][1].split("ã€Š")[1].split("ã€‹")[0]}ï¼Œé€šè¿‡{random.choice(["çŸ¥è¯† grounding", "å¯¹æ¯”å­¦ä¹ "])}ç¼“è§£{core_problem}ï¼›
- åŸºäºæ¨¡å‹ç»“æ„ä¼˜åŒ–çš„æ–¹æ³•ï¼š{literature_list[1][0]}çš„ç ”ç©¶èšç„¦äº{core_problem}çš„å¯è§£é‡Šæ€§ï¼Œæå‡ºäº†{random.choice(["å…ƒå­¦ä¹ æ¡†æ¶", "ç‰¹å¾å¯¹é½ç­–ç•¥"])}ï¼›
- åŸºäºæç¤ºå·¥ç¨‹çš„æ–¹æ³•ï¼š{literature_list[2][0]}æ¢ç´¢äº†ä½èµ„æºåœºæ™¯ä¸‹çš„{core_problem}è§£å†³æ€è·¯ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†å‚è€ƒã€‚

#### 3. ç°æœ‰ç ”ç©¶ä¸è¶³
- ç°æœ‰æ–¹æ³•åœ¨{random.choice(["ä½èµ„æºåœºæ™¯", "å¤æ‚ä»»åŠ¡"])}ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼›
- ç¼ºä¹å¯¹{core_problem}äº§ç”Ÿæœºåˆ¶çš„æ·±å…¥åˆ†æä¸å¯è§£é‡Šæ€§éªŒè¯ï¼›
- è·¨é¢†åŸŸèåˆçš„è§£å†³æ–¹æ¡ˆå°šæœªå½¢æˆä½“ç³»åŒ–ç ”ç©¶ã€‚

#### 4. æœ¬æ–‡ç ”ç©¶åˆ‡å…¥ç‚¹
é’ˆå¯¹ä¸Šè¿°ä¸è¶³ï¼Œæœ¬ç ”ç©¶æ‹Ÿä»{random.choice(["å¤šæ¨¡æ€èåˆ", "è½»é‡åŒ–æ¨¡å‹"])}è§†è§’å‡ºå‘ï¼Œæå‡ºé€‚ç”¨äº{field}çš„{core_problem}è§£å†³æ–¹æ³•ã€‚
    """


def generate_abstract(client, field, core_problem, topic):
    """ç”Ÿæˆæ‘˜è¦ï¼ˆAPIä¼˜å…ˆï¼Œæ— åˆ™å…œåº•ï¼‰"""
    if client:
        prompt = f"""
        åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆè§„èŒƒçš„å­¦æœ¯è®ºæ–‡æ‘˜è¦ï¼ˆçº¦300å­—ï¼‰ï¼š
        1. å­¦ç§‘é¢†åŸŸï¼š{field}
        2. æ ¸å¿ƒç ”ç©¶é—®é¢˜ï¼š{core_problem}
        3. ç ”ç©¶é€‰é¢˜ï¼š{topic}
        4. è¦æ±‚ï¼šåŒ…å«ã€Œç ”ç©¶èƒŒæ™¯ã€ã€Œç ”ç©¶æ–¹æ³•ã€ã€Œå®éªŒç»“æœã€ã€Œç ”ç©¶ç»“è®ºã€4éƒ¨åˆ†ï¼Œæ•°æ®åˆç†è™šæ„ï¼Œç¬¦åˆå­¦æœ¯è§„èŒƒã€‚
        """
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,
                max_tokens=600
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            st.warning(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å…œåº•æ•°æ®ï¼š{str(e)}")

    # å…œåº•é€»è¾‘
    return f"""
### è®ºæ–‡æ‘˜è¦
**ç ”ç©¶èƒŒæ™¯**ï¼š{field}æ˜¯å½“å‰äººå·¥æ™ºèƒ½é¢†åŸŸçš„ç ”ç©¶çƒ­ç‚¹ï¼Œ{core_problem}é—®é¢˜å·²æˆä¸ºåˆ¶çº¦è¯¥é¢†åŸŸæŠ€æœ¯è½åœ°çš„å…³é”®ç“¶é¢ˆã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†{random.choice(["ä½èµ„æº", "å¤æ‚åœºæ™¯"])}ä¸‹çš„{core_problem}æ—¶ï¼Œå­˜åœ¨{random.choice(["æ€§èƒ½ä¸è¶³", "å¯è§£é‡Šæ€§å·®"])}ç­‰é—®é¢˜ã€‚
**ç ”ç©¶æ–¹æ³•**ï¼šæœ¬æ–‡æå‡ºäº†{topic.split("ï¼š")[-1] if "ï¼š" in topic else "ä¸€ç§åŸºäºæ–°å‹æ¡†æ¶çš„"}æ–¹æ³•ï¼Œé€šè¿‡{random.choice(["çŸ¥è¯†é”šå®š", "ç‰¹å¾å¯¹é½", "å…ƒå­¦ä¹ "])}ç­–ç•¥ä¼˜åŒ–æ¨¡å‹è¾“å‡ºï¼Œå¢å¼ºå¯¹{core_problem}çš„æŠ‘åˆ¶/è§£å†³èƒ½åŠ›ã€‚
**å®éªŒç»“æœ**ï¼šåœ¨{random.choice(["å…¬å¼€åŸºå‡†æ•°æ®é›†", "è‡ªå»ºæ•°æ®é›†"])}ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•ç›¸è¾ƒäº{random.choice(["Li et al., 2024", "Zhang et al., 2023"])}çš„åŸºçº¿æ¨¡å‹ï¼Œ{random.choice(["å‡†ç¡®ç‡æå‡12.5%", "å¹»è§‰ç‡é™ä½18.3%", "F1å€¼æé«˜9.7%"])}ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
**ç ”ç©¶ç»“è®º**ï¼šè¯¥æ–¹æ³•ä¸ºè§£å†³{field}ä¸­çš„{core_problem}é—®é¢˜æä¾›äº†æ–°çš„æ€è·¯ï¼Œå¯è¿›ä¸€æ­¥æ‹“å±•è‡³{random.choice(["å¤šæ¨¡æ€ä»»åŠ¡", "å·¥ä¸šçº§åº”ç”¨åœºæ™¯"])}ã€‚
    """


def format_citation(literature, format_type):
    """ç”ŸæˆæŒ‡å®šæ ¼å¼çš„å¼•ç”¨"""
    formatted_citations = []
    year = literature[0].split(", ")[1] if ", " in literature[0] else "2024"
    for auth, title, journal in literature:
        citation = CITATION_FORMATS[format_type].format(
            authors=auth,
            year=year,
            title=title,
            journal=journal
        )
        formatted_citations.append(citation)
    return formatted_citations


# -------------------------- é¡µé¢å¸ƒå±€ï¼ˆé‡ç‚¹ï¼šç½‘é¡µè¾“å…¥APIï¼‰ --------------------------
# ä¾§è¾¹æ ï¼šç ”ç©¶å‚æ•° + APIå¯†é’¥è¾“å…¥
st.sidebar.header("ğŸ“‹ ç ”ç©¶å‚æ•°é…ç½®")
field = st.sidebar.text_input("å­¦ç§‘é¢†åŸŸ", placeholder="å¦‚ï¼šè®¡ç®—æœºç§‘å­¦/æœºå™¨å­¦ä¹ /å¤§æ¨¡å‹å¹»è§‰æŠ‘åˆ¶")
research_basis = st.sidebar.selectbox("å·²æœ‰åŸºç¡€", ["å·²å®Œæˆæ–‡çŒ®è°ƒç ”", "æ­£åœ¨è¿›è¡Œå®éªŒ", "éœ€ç¡®å®šé€‰é¢˜"])
core_problem = st.sidebar.text_input("æ ¸å¿ƒç ”ç©¶é—®é¢˜", placeholder="å¦‚ï¼šç°æœ‰æ–¹æ³•åœ¨ä½èµ„æºåœºæ™¯ä¸‹æ€§èƒ½ä¸‹é™")
citation_format = st.sidebar.selectbox("å¼•ç”¨æ ¼å¼", ["APA 7th", "GB/T 7714", "MLA 9th"])
output_choice = st.sidebar.multiselect(
    "è¾“å‡ºå†…å®¹",
    ["åˆ›æ–°é€‰é¢˜å»ºè®®", "æ–‡çŒ®ç»¼è¿°æ¡†æ¶", "è®ºæ–‡æ‘˜è¦åˆç¨¿"],
    default=["åˆ›æ–°é€‰é¢˜å»ºè®®", "æ–‡çŒ®ç»¼è¿°æ¡†æ¶", "è®ºæ–‡æ‘˜è¦åˆç¨¿"]
)

# æ ¸å¿ƒï¼šä¾§è¾¹æ æ‰‹åŠ¨è¾“å…¥APIå¯†é’¥ï¼ˆå¯†ç æ¡†éšè—ï¼‰
st.sidebar.divider()
st.sidebar.header("ğŸ”‘ OpenAI API é…ç½®")
api_key = st.sidebar.text_input(
    "API Key",
    type="password",  # è¾“å…¥æ—¶éšè—ï¼Œä¿æŠ¤å¯†é’¥
    placeholder="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
    help="è·å–åœ°å€ï¼šhttps://platform.openai.com/api-keys"
)
st.sidebar.markdown('<div class="api-tip">âœ… å¡«å†™æœ‰æ•ˆå¯†é’¥å¯ç”Ÿæˆé«˜è´¨é‡å­¦æœ¯å†…å®¹ï¼Œä¸å¡«åˆ™ç”¨æ¨¡æ‹Ÿæ•°æ®</div>',
                    unsafe_allow_html=True)

# ç”ŸæˆæŒ‰é’®
generate_btn = st.sidebar.button("ğŸš€ ç”Ÿæˆå­¦æœ¯çµæ„Ÿ", type="primary")

# ä¸»é¡µé¢æ ‡é¢˜
st.title("ğŸ“š ScholarMind å­¦æœ¯çµæ„Ÿå¼•æ“")
st.divider()

# ç”Ÿæˆç»“æœå±•ç¤º
if generate_btn:
    # åŸºç¡€æ ¡éªŒ
    if not field or not core_problem:
        st.error("âš ï¸ è¯·å…ˆå¡«å†™ã€Œå­¦ç§‘é¢†åŸŸã€å’Œã€Œæ ¸å¿ƒç ”ç©¶é—®é¢˜ã€ï¼")
    else:
        # åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆä»…åŸºäºç½‘é¡µè¾“å…¥çš„APIå¯†é’¥ï¼‰
        client = init_openai_client(api_key)

        # åŠ è½½çŠ¶æ€
        with st.spinner("æ­£åœ¨ç”Ÿæˆå­¦æœ¯å†…å®¹ï¼Œè¯·ç¨å€™..."):
            # è·å–æ–‡çŒ®
            literature = get_literature(field.strip())

            # åˆ†æ å±•ç¤ºç»“æœ
            col1, col2 = st.columns([2, 1])
            with col1:
                # ç”Ÿæˆé€‰é¢˜
                st.subheader("ğŸ¯ åˆ›æ–°é€‰é¢˜å»ºè®®")
                topics = generate_topics(client, field, core_problem)
                for i, topic in enumerate(topics, 1):
                    st.markdown(f"""
                    <div class="result-card">
                        <strong>é€‰é¢˜{i}ï¼š</strong> {topic}
                    </div>
                    """, unsafe_allow_html=True)

                # ç”Ÿæˆç»¼è¿°
                if "æ–‡çŒ®ç»¼è¿°æ¡†æ¶" in output_choice:
                    st.subheader("ğŸ“– æ–‡çŒ®ç»¼è¿°æ¡†æ¶")
                    review = generate_literature_review(client, field, core_problem, literature)
                    st.markdown(f'<div class="result-card">{review}</div>', unsafe_allow_html=True)

                # ç”Ÿæˆæ‘˜è¦
                if "è®ºæ–‡æ‘˜è¦åˆç¨¿" in output_choice:
                    st.subheader("ğŸ“ è®ºæ–‡æ‘˜è¦åˆç¨¿")
                    abstract = generate_abstract(client, field, core_problem, topics[0])
                    st.markdown(f'<div class="result-card">{abstract}</div>', unsafe_allow_html=True)

            with col2:
                # æ–‡çŒ®å¼•ç”¨
                st.subheader("ğŸ“œ æ ¸å¿ƒæ–‡çŒ®å¼•ç”¨")
                formatted_cites = format_citation(literature, citation_format)
                for i, cite in enumerate(formatted_cites, 1):
                    st.markdown(f'<div class="citation">{i}. {cite}</div>', unsafe_allow_html=True)

                # å¯¼å‡ºåŠŸèƒ½
                st.subheader("ğŸ’¾ å¯¼å‡ºå†…å®¹")
                export_all = "\n\n".join([
                    "=== åˆ›æ–°é€‰é¢˜å»ºè®® ===",
                    "\n".join(topics),
                    "=== æ–‡çŒ®ç»¼è¿°æ¡†æ¶ ===",
                    review if "æ–‡çŒ®ç»¼è¿°æ¡†æ¶" in output_choice else "",
                    "=== è®ºæ–‡æ‘˜è¦åˆç¨¿ ===",
                    abstract if "è®ºæ–‡æ‘˜è¦åˆç¨¿" in output_choice else "",
                    "=== æ ¸å¿ƒæ–‡çŒ®å¼•ç”¨ ===",
                    "\n".join(formatted_cites)
                ])
                st.download_button(
                    label="ä¸‹è½½å…¨éƒ¨å†…å®¹ï¼ˆTXTï¼‰",
                    data=export_all,
                    file_name=f"ScholarMind_æˆæœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain"
                )

# åº•éƒ¨æç¤º
st.divider()

st.caption("ğŸ’¡ æç¤ºï¼šç”Ÿæˆå†…å®¹ä»…ä¸ºå­¦æœ¯çµæ„Ÿå‚è€ƒï¼Œéœ€ç»“åˆå®é™…ç ”ç©¶éªŒè¯ï¼›APIå¯†é’¥ä»…åœ¨æœ¬æ¬¡ä¼šè¯æœ‰æ•ˆï¼Œä¸ä¼šå­˜å‚¨ã€‚")
